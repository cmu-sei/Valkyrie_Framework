{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Valkyrie Framework","text":"<p>Developed by Carnegie Mellon University's Software Engineering Institute (SEI), the Valkyrie Framework is an open source suite of tools that enables hunt teams to locate and identify hidden cybersecurity threats lurking in network traffic using machine learning and other advanced analytics.</p> About the Framework <p>There are two tools in the Framework currently, but we expect more in the future.</p> <p>The Source Code Repository is hosted on GitHub.</p>"},{"location":"#beacon-huntress","title":"Beacon Huntress","text":"<p>Beacon Huntress is designed to identify malicious network beacons. But first, what are network beacons? We define network beacons as events that occur (and recur) on a timed interval. Network beacons can be compared to a heartbeat signal over time. While there are legitimate uses for network beacons (e.g., WiFi, obtaining instructions from an API, beaming telemetry data home), network beaconing can also be a byproduct of malware connecting to a command and control (C2) server. Malware communicating with a C2 server can pass information or request new instructions.</p> <p>Beacons can be difficult to spot with traditional security tools -- especially those that communicate infrequently. Beacon Huntress finds beacons within Zeek logs using machine learning algorithms that identify clustering patterns.</p> <p>Beacon Huntress uses a combination of Python and Machine Learning to find potential beacons.</p>"},{"location":"#ip-maven","title":"IP Maven","text":"<p>IP Maven is a DNS service that provides detailed information about IP addresses and their associated netblock records, both online and offline.</p> <p>By combining traditional Zeek DNS logs with enriched netblock information, IP Maven delivers a holistic view of network traffic.</p>"},{"location":"#reporting-bugs","title":"Reporting Bugs","text":"<p>Find a bug? Please report it through the issue tracker. Include detailed steps for reproducing the issue and include any relevant error messages.</p>"},{"location":"#requesting-features","title":"Requesting Features","text":"<p>Have a feature request? Submit new ideas through the issue tracker with a description of how it could benefit the community.</p>"},{"location":"#license","title":"License","text":"<p>[DISTRIBUTION STATEMENT A] This material has been approved for public release and unlimited distribution. Copyright 2023 Carnegie Mellon University. See the license file for more details.</p>"},{"location":"beacon_huntress/","title":"Welcome to Beacon Huntress","text":"<p>Beacon Huntress uses a combination of Python and Machine Learning to identify potential beacons.</p>"},{"location":"beacon_huntress/#fastslow-beacon","title":"Fast/Slow Beacon","text":"<p>Throughout this documentation you will see the terms Fast Beacon and Slow Beacon. These terms describe two different beaconing patterns based upon the time interval that passes between connection events.</p> <ul> <li>A Fast Beacon is a beacon that has a short interval time. We consider anything &lt;= 5 minutes to be a Fast Beacon.</li> <li>A Slow Beacon is a beacon that has a long interval time. We consider anything &gt; 5 minutes to be a Slow Beacon.</li> </ul> Note <p>Beacon Huntress was tested using HTTP/HTTPS beacons. This version of Beacon Huntress has not yet been tested using DNS beacons -- although it should work.</p>"},{"location":"beacon_huntress/#how-to-use-beacon-huntress","title":"How to use Beacon Huntress","text":"<p>Beacon Huntress can be used in two ways: via Docker or a Jupyter Notebook.</p> Warning <p>For the purposes of this documentation, Beacon Huntress is assumed to have been downloaded via Git.</p> <p>To run Beacon Huntress, you will need to answer the following questions:</p> <ol> <li>Where are my Zeek logs located?</li> <li>Do I want to filter out any connections in my logs?</li> <li>How many minutes do potential beacons wait before calling back? Are the beacons Fast or Slow?</li> <li>How many connections does a potential beacon need to have in order to be reported?</li> </ol> <p>With answers to these questions, you can begin to configure Beacon Huntress to run. Check the Tutorial section for an example.</p>"},{"location":"beacon_huntress/#beacon-huntress-default-settings","title":"Beacon Huntress Default Settings","text":"<ul> <li>Raw Bro/Zeek logs are copied to /tmp/raw/data.</li> <li>All connections using ports 80 and 443 are included.</li> <li>Local connections, i.e., connections with 127.0.0.1 as the source or destination, are excluded.</li> <li>Various high-usage top sites are excluded. See Default Filtered Hosts for the list of filtered sites.</li> </ul>"},{"location":"beacon_huntress/#docker-setup","title":"Docker Setup","text":"<p>The quickest way to set up this software is via docker-compose.</p> <p>Before starting, please ensure the following:</p> <ul> <li>Docker is installed and running (check with <code>docker --version</code> in the terminal).</li> <li>Docker-compose is installed (check with <code>docker-compose --version</code> or <code>docker compose --version</code> in the terminal).</li> <li>You have Zeek connection logs available.</li> <li>You have downloaded the Valkyrie Framework.</li> </ul> <p>Good to go? Next, proceed with the following in the terminal:</p> <ol> <li><code>cd</code> to the Valkyrie Framework directory</li> <li>Run <code>docker-compose up -d</code> or <code>docker compose up -d</code> depending on your Docker version. This will create the database, and may take some time to complete.</li> <li>Note that some Docker volumes were created.</li> <li><code>_mysql</code> is your database, so that if the container stops, you do not lose previously saved data</li> <li>Visit http://127.0.0.1:8000 in your web browser to access the Beacon Huntress Web UI.</li> <li>Continue to the Tutorial section for examples on how to start using Beacon Huntress.</li> </ol> <p>For troubleshooting, check <code>docker logs -f beacon_huntress</code> to access Web UI logging.</p> Note <p>Beacon Huntress Docker containers will fail if you attempt to use any of the following ports:</p> <ul> <li>3000 (Grafana)</li> <li>3306 (MySQL)</li> <li>8000 (Django)</li> </ul> <p>Once you have the list of IP's from the dashboard you should conduct further investigation and analysis of the Potential Beacons using tools such as nslookup, PCAP, etc. to assess their veracity. Depending on network traffic and Beacon Huntress configuration, some connections identified as Potential Beacons may not be malicious. You can filter these sites out of the results. For more details see the User Interface documentation.</p> <p>See Tutorial for running Beacon Huntress.</p>"},{"location":"beacon_huntress/#license","title":"License","text":"<p>[DISTRIBUTION STATEMENT A] This material has been approved for public release and unlimited distribution. Copyright 2023 Carnegie Mellon University. See the license file for more details.</p>"},{"location":"beacon_huntress/algorithms/","title":"Algorithms Used Within Beacon Huntress","text":"<p>Beacon Huntress can be configured to search for beacons using the algorithms below. Each Machine Learning (ML) algorithm has its own unique parameters and is used to search for slow or fast beacons based on time intervals.</p>"},{"location":"beacon_huntress/algorithms/#advanced-search-for-beacons","title":"Advanced Search for Beacons","text":"<p>Below are the current algorithms that can be used when searching for beacons.</p> <ul> <li>Detailed Cluster Search</li> <li>Use with Fast or Slow Beacons</li> <li>Hierarchical Search</li> <li>Use with Fast Beacons</li> <li>Quick Cluster Search</li> <li>Use with Fast or Slow Beacons</li> </ul> Note <p>Algorithms can be set by using the <code>cluster_type</code> option in config.conf. The default algorithm is Quick Cluster Search with Slow Beacon parameters used for dbscan_by_variance().</p>"},{"location":"beacon_huntress/algorithms/#beacon-searches","title":"Beacon Searches","text":""},{"location":"beacon_huntress/algorithms/#detailed-cluster-search","title":"Detailed Cluster Search","text":"<p>Cluster Search is also known as DBSCAN, which stands for Density-Based Spatial Clustering of Applications with Noise. DBSCAN can identify clusters of different sizes within large data samples that contain noise and outliers. DBSCAN primarily uses two parameters: Minimum Points and EPS (Epsilon). The Minimum Points parameter represents the minimum number of data points (the threshold) that must be clustered together for a region to be considered dense. EPS is the maximum distance between two data points for them to be considered part of the same cluster.</p> <ul> <li>DBSCAN clustering is a good choice for searching either Fast Beacons or Slow Beacons. However, this is the slowest running algorithm.</li> </ul> <p> image source</p>"},{"location":"beacon_huntress/algorithms/#parameters","title":"Parameters","text":"<ul> <li> <p>Minimum Delta Time (int)   The minimum time interval between connection requests (in minutes) for your search.</p> </li> <li> <p>Time Spans (list)    Spans of time that you wish to search, in list format.  Example: Will search within two time spans, 0-5 mins and 5-10 mins: [[0, 5], [5, 10]] <li> <p>Minimum Cluster Points (int)   The minimum number of cluster points/connections needed to identify a potential beacon.</p> </li> <li> <p>Likelihood Percentage (int)    The likelihood percentage used as a threshold by the Machine Learning algorithm in order to flag a potential beacon.</p> </li> <p>Below are two examples for finding fast and slow beacons using DBSCAN clustering.</p>"},{"location":"beacon_huntress/algorithms/#fast-beacon-search","title":"Fast Beacon Search","text":"<p>Searching for beacons with 70% likelihood, time spans (0-5 mins, 2-15 mins, 15-35 mins, 30-60 mins), at least 10 connections, and minimum delta time of 1 minute.</p> <pre><code>Minimum Delta Time = 1\nTime Spans = [[0, 5], [2, 15], [15, 35], [30, 60]]\nMinimum Cluster Points = 10\nLikelihood Percentage = 70\n</code></pre> <p></p>"},{"location":"beacon_huntress/algorithms/#slow-beacon-search","title":"Slow Beacon Search","text":"<p>Searching for beacons with 70% likelihood, time spans (0-5 mins, 2-15 mins, 15-35 mins, 30-60 mins), at least 10 connections, and minimum delta time of 20 minutes.</p> <pre><code>Minimum Delta Time = 20\nTime Spans = [[0, 5], [2, 15], [15, 35], [30, 60]]\nMinimum Cluster Points = 10\nLikelihood Percentage = 70\n</code></pre> <p></p>"},{"location":"beacon_huntress/algorithms/#hierarchical-search","title":"Hierarchical Search","text":"<p>Hierarchical Search uses agglomerative clustering, which is a hierarchical clustering technique used to group objects based on similarity. Each item is treated as a singleton cluster, and clusters that are sufficiently similar are merged together into a larger cluster, working from the bottom up. This process continues until all of the clusters are placed into a single large cluster (see image below).</p> <ul> <li>Agglomerative clustering works well when searching for Fast Beacons.</li> </ul> <p> image source</p>"},{"location":"beacon_huntress/algorithms/#parameters_1","title":"Parameters","text":"<ul> <li> <p>Maximum Variance Percentage (int)   Variance threshold for any potential beacons.</p> </li> <li> <p>Beacon Callback Count (int)   Minimum number of delta records to search.</p> </li> <li> <p>Clustering Factor Percentage (int)   The likelihood percentage for a cluster.</p> </li> <li> <p>Process Lines (list)   Line amounts to process at a time, in list format.</p> </li> <li> <p>Minimum Callback Time (ms) (int)   Minimum delta time to search by, in milliseconds.</p> </li> </ul> <p>Below are two examples for finding fast and slow beacons using agglomerative clustering.</p> Note <p>Hierarchical Search is NOT a recommended algorithm for searching for Slow Beacons.</p>"},{"location":"beacon_huntress/algorithms/#fast-beacon-search_1","title":"Fast Beacon Search","text":"<p>Searching for beacons with 70% likelihood, 12% max variance, at least 10 connections, and delta time of 60 seconds.</p> <pre><code>Maximum Variance Percentage = 12\nBeacon Callback Count =  10\nClustering Factor Percentage = 70\nProcess Lines = 1\nMinimum Callback Time (ms) = 60000\n</code></pre> <p></p>"},{"location":"beacon_huntress/algorithms/#slow-beacon-search_1","title":"Slow Beacon Search","text":"<p>Searching for beacons with 70% likelihood, 12% max variance, at least 10 connections, and delta time of 15 minutes.</p> <pre><code>Maximum Variance Percentage = 12\nBeacon Callback Count =  10\nClustering Factor Percentage = 70\nProcess Lines = 1\nMinimum Callback Time (ms) = 900000\n</code></pre> <p></p>"},{"location":"beacon_huntress/algorithms/#_1","title":"Algorithms","text":""},{"location":"beacon_huntress/algorithms/#quick-cluster-search","title":"Quick Cluster Search","text":"<p>Quick Cluster Search uses the same principles as Detailed Cluster Search but some records will be filtered out before the scan if they surpass the user-set variance percentage. If the variance is above the configured threshold, it is excluded from the scan. This feature provides all of the benefits of a DBSCAN without the performance overhead.</p> <ul> <li>DBSCAN by Variance clustering is a good choice for searching either Fast Beacons or Slow Beacons.</li> <li>This provides a performance increase over Detailed Cluster Search because some connections will be pre-filtered by the variance setting.</li> </ul>"},{"location":"beacon_huntress/algorithms/#parameters_2","title":"Parameters","text":"<ul> <li> <p>Average Delta Time (int)   Average delta time to include in the search using your delta column. Less than or equal (&lt;=).</p> </li> <li> <p>Connection Count (int)   Total connection count for filtering. Greater than or equal (&gt;=).</p> </li> <li> <p>Time Span Average (int)    The percentage to increase and decrease from the connections total delta span. Example: 15 will decrease 15% from the minimum and maximum delta span. delta min = 5 delta max = 10 span min = 4.25 (5 - (5 _ 15%)) span max = 11.5 (10 + (10 _ 15%)) <li> <p>Variance Percentage (int)   Total variance percentage for filtering. Greater than or equal (&gt;=). Default = 4</p> </li> <li> <p>Minimum Likelihood Percentage (int)    Likelihood value (threshold) used to identify a potential beacon.</p> </li> <p>Below are two examples for finding fast and slow beacons using DBSCAN by variance clustering (Quick Cluster).</p>"},{"location":"beacon_huntress/algorithms/#fast-beacon-search_2","title":"Fast Beacon Search","text":"<p>Searching for beacons with 70% likelihood, at least 10 connections, 15% time span average, minimum variance of 15% and minimum delta time of 5 minutes.</p> <pre><code>Average Delta Time = 5\nConnection Count = 10\nTime Span Average = 15\nVariance Percentage = 15\nMinimum Likelihood Percentage = 70\n</code></pre> <p></p>"},{"location":"beacon_huntress/algorithms/#slow-beacon-search_2","title":"Slow Beacon Search","text":"<p>Searching for beacons with 70% likelihood, at least 10 connections, 15% time span average, minimum variance of 15% and minimum delta time of 20 minutes. Note that this will also search for fast beacons, as avg_delta &lt;= value encompasses both fast and slow.</p> <pre><code>Average Delta Time = 20\nConnection Count = 10\nTime Span Average = 15\nVariance Percentage = 15\nMinimum Likelihood Percentage = 70\n</code></pre> <p></p>"},{"location":"beacon_huntress/api/","title":"Beacon Huntress API","text":"<p>API has been added for</p> <ul> <li>API<ul> <li>Application<ul> <li>Version</li> <li>Configuration</li> </ul> </li> <li>Searches<ul> <li>Quick Cluster</li> <li>Detail Cluster</li> <li>Hierarchical</li> </ul> </li> <li>Results<ul> <li>Beacon Groups</li> <li>Beacon Results</li> <li>Log File</li> <li>Filter Beacon</li> </ul> </li> </ul> </li> <li>Interactive API Docs</li> <li>Coding Example<ul> <li>Run a Beacon Search</li> </ul> </li> </ul>"},{"location":"beacon_huntress/api/#application","title":"Application","text":""},{"location":"beacon_huntress/api/#version","title":"Version","text":"<p>Beacon Huntress version</p> <ul> <li>Return Values<ul> <li>title: Application title</li> <li>version: Beacon Huntress version number</li> <li>description: Beacon Huntress description</li> </ul> </li> <li>Example Code <pre><code>import requests\n\nurl = \"http://127.0.0.1:8000/api/application/version\"\n\nresponse = requests.get(url)\nval = response.json()\nprint(val)\n</code></pre></li> </ul>"},{"location":"beacon_huntress/api/#configuration","title":"Configuration","text":"<p>Beacon Huntress configuration</p> <ul> <li>Return Values<ul> <li>Beacon Huntress Configuration: Beacon Huntress Configuration</li> </ul> </li> <li>Example Code <pre><code>import requests\n\nurl = \"http://127.0.0.1:8000/api/application/configuration\"\n\nresponse = requests.get(url)\nval = response.json()\nprint(val)\n</code></pre></li> </ul>"},{"location":"beacon_huntress/api/#searches","title":"Searches","text":""},{"location":"beacon_huntress/api/#quick-cluster","title":"Quick Cluster","text":"<p>Run Beacon Huntress quick cluster search.</p> <ul> <li>Input Values<ul> <li>log_type: Log Type parameter (Zeek Connection = conn)</li> <li>log_dir: Log directory location</li> <li>delta: Average callback time in minutes</li> <li>call_back: The minimum number of connection callbacks</li> <li>percent: The minimum percentage of cluster points</li> <li>span_avg: The percentage for the span of EPS</li> <li>variance: The maximum percentage of jitter that is allowed</li> <li>start_dte: The start date time</li> <li>end_dte: The end date time</li> <li>zip: Is the file a zip file (True or False)</li> <li>verbose: Verbose logging (True of False)</li> </ul> </li> <li>Return Values<ul> <li>beacon_group: Beacon Huntress run results group</li> <li>cnt: Number of potential beacons</li> <li>log_file: Beacon Huntress run results log file</li> </ul> </li> <li>Example Code <pre><code>import requests\nimport json\n\nurl = \"http://127.0.0.1:8000/api/searches/quick_cluster\"\npayload = {\n\"log_type\": \"conn\",\n\"log_dir\": \"/tutorial\",\n\"delta\": 20,\n\"call_back\": 10,\n\"percent\": 85,\n\"span_avg\": 12,\n\"variance\": 15,\n\"start_dte\": \"\",\n\"end_dte\": \"\",\n\"zip\": False,\n\"verbose\": False\n}\npayload = json.dumps(payload)\n\nresponse = requests.post(url, data=payload)\nval = response.json()\nprint(val)\n</code></pre></li> </ul>"},{"location":"beacon_huntress/api/#detail-cluster","title":"Detail Cluster","text":"<p>Beacon Huntress detailed cluster search.</p> <ul> <li>Input Values<ul> <li>log_type: Log Type parameter (Zeek Connection = conn)</li> <li>log_dir: Log directory location</li> <li>delta: Average callback time in minutes</li> <li>call_back: The minimum number of connection callbacks</li> <li>percent: The minimum percentage of cluster points</li> <li>spans: The time spans to search in list form (e.g [[0, 5], [2, 15], [15, 35], [30, 60]])</li> <li>variance: The maximum percentage of jitter that is allowed</li> <li>start_dte: The start date time</li> <li>end_dte: The end date time</li> <li>zip: Is the file a zip file (True or False)</li> <li>verbose: Verbose logging (True of False)</li> </ul> </li> <li>Return Values<ul> <li>beacon_group: Beacon Huntress run results group</li> <li>cnt: Number of potential beacons</li> <li>log_file: Beacon Huntress run results log file</li> </ul> </li> <li>Example Code <pre><code>import requests\nimport json\n\nurl = \"http://127.0.0.1:8000/api/searches/detailed_cluster\"\npayload = {\n\"log_type\": \"conn\",\n\"log_dir\": \"/tutorial\",\n\"delta\": 20,\n\"time_spans\": [\n    [0,5],\n    [2,15],\n    [15,35],\n    [30,60]\n    ],\n\"call_back\": 10,\n\"percent\": 85,\n\"start_dte\": \"\",\n\"end_dte\": \"\",\n\"zip\": False,\n\"verbose\": False\n}\npayload = json.dumps(payload)\n\n# Run Quick Cluster Search\nresponse = requests.post(url, data=payload)\nval = response.json()\nprint(val)\n</code></pre></li> </ul>"},{"location":"beacon_huntress/api/#hierarchical","title":"Hierarchical","text":"<p>Beacon Huntress hierarchical search.</p> <ul> <li>Input Values<ul> <li>log_type: Log Type parameter (Zeek Connection = conn)</li> <li>log_dir: Log directory location</li> <li>delta: Average callback time in minutes</li> <li>line_amounts: The amount of lines to process (e.g. [1])</li> <li>call_back: The minimum number of connection callbacks</li> <li>variance: The maximum percentage of jitter that is allowed</li> <li>percent: The minimum percentage of cluster points</li> <li>start_dte: The start date time</li> <li>end_dte: The end date time</li> <li>zip: Is the file a zip file (True or False)</li> <li>verbose: Verbose logging (True of False)</li> </ul> </li> <li>Return Values<ul> <li>beacon_group: Beacon Huntress run results group</li> <li>cnt: Number of potential beacons</li> <li>log_file: Beacon Huntress run results log file</li> </ul> </li> <li>Example Code <pre><code>import requests\nimport json\n\nurl = \"http://127.0.0.1:8000/api/searches/hierarchical\"\npayload = {\n\"log_type\": \"conn\",\n\"log_dir\": \"/tutorial\",\n\"delta\": 20,\n\"line_amounts\": [\n    1\n],\n\"call_back\": 10,\n\"variance\": 15,\n\"percent\": 85,\n\"start_dte\": \"\",\n\"end_dte\": \"\",\n\"zip\": False,\n\"verbose\": False\n}\npayload = json.dumps(payload)\n\n# Run Quick Cluster Search\nresponse = requests.post(url, data=payload)\nval = response.json()\nprint(val)\n</code></pre></li> </ul>"},{"location":"beacon_huntress/api/#results","title":"Results","text":""},{"location":"beacon_huntress/api/#beacon-groups","title":"Beacon Groups","text":"<p>Get Beacon Huntress search groups.</p> <ul> <li>Return Values<ul> <li>beacon_group: Results group_id to be used for /beacon_groups</li> <li>date: Date of search</li> <li>beacon_count: Number of potential beacons</li> <li>log_file: Results log_file name to used for get_log_file</li> </ul> </li> <li>Example Code <pre><code>import requests\n\nurl = \"http://127.0.0.1:8000/api/results/beacon_groups\"\n\nresponse = requests.get(url)\nval = response.json()\nprint(val)\n</code></pre></li> </ul>"},{"location":"beacon_huntress/api/#beacon-results","title":"Beacon Results","text":"<p>Get or Delete Beacon Results</p> <ul> <li>Input Values<ul> <li>beacon_group: Beacon Group UUID</li> </ul> </li> <li>Return Values<ul> <li>ID: Unique row identifier</li> <li>Source IP: Source IP address</li> <li>Destination IP: Destination IP address</li> <li>Port: Destination Port ID</li> <li>Score: Clustered score</li> <li>DNS: DNS name</li> <li>Connection Count: Number of connection for each unique Source IP, Destination IP and Port.</li> <li>First Occurrence: Minimum date for each unique Source IP, Destination IP and Port.</li> <li>Last Occurrence: Maximum date for each unique Source IP, Destination IP and Port.</li> </ul> </li> <li>Example Code <pre><code>import requests\n\nurl = \"http://127.0.0.1:8000/api/results/beacon_results\"\n\n# Get Results\nresponse = requests.get(url, params={\"beacon_group\": \"9a42fb53-ceac-44b2-afae-d89d133679e2\"})\n\n# Delete Results\n#response = requests.delete(url, params={\"beacon_group\": \"9a42fb53-ceac-44b2-afae-d89d133679e2\"})\n\nval = response.json()\nprint(val)\n</code></pre></li> </ul>"},{"location":"beacon_huntress/api/#top-talkers","title":"Top Talkers","text":"<p>Get Beacon Huntress Top Talkers</p> <ul> <li>Input Values<ul> <li>beacon_group: Beacon Group UUID</li> </ul> </li> <li>Return Values<ul> <li>ID: Unique row identifier</li> <li>Source IP: Source IP address</li> <li>Destination IP: Destination IP address</li> <li>Port: Destination Port ID</li> <li>Total Number of Connections: Total number of connect for each unique Source IP, Destination IP and Port.</li> </ul> </li> <li>Example Code <pre><code>import requests\n\nurl = \"http://127.0.0.1:8000/api/results/top_talkers\"\n\n# Get Top Talkers\nresponse = requests.get(url, params={\"beacon_group\": \"9a42fb53-ceac-44b2-afae-d89d133679e2\"})\n\nval = response.json()\nprint(val)\n</code></pre></li> </ul>"},{"location":"beacon_huntress/api/#log-file","title":"Log File","text":"<p>Get or Delete Log File</p> <ul> <li>Input Values<ul> <li>log_file: Beacon run log file</li> </ul> </li> <li>Return Values<ul> <li>file_content: Log file content</li> </ul> </li> <li>Example Code <pre><code>import requests\n\nurl = \"http://127.0.0.1:8000/api/results/log_file\"\n\n# Get Log File\nresponse = requests.get(url, params={\"log_file\": \"log_1752679403\"})\n\n# Delete Log File\n#response = requests.delete(url, params={\"log_file\": \"log_1752679403\"})\n\nval = response.json()\nprint(val)\n</code></pre></li> </ul>"},{"location":"beacon_huntress/api/#filter-beacon","title":"Filter Beacon","text":"<p>Get, Add or Delete Filtered Hosts</p> <ul> <li>Input Values (Add or Delete)<ul> <li>ip: IP to filter</li> </ul> </li> <li>Return Values<ul> <li>Add<ul> <li>Filtered: Boolean</li> <li>Message: Short description</li> </ul> </li> <li>Deleted<ul> <li>Deleted: Boolean</li> <li>Message: Short description</li> </ul> </li> <li>Get<ul> <li>IP: Filter host IP</li> <li>DNS: Dns name</li> <li>Description: Description for filtered host</li> <li>Filtered_Date: Date of filtered host</li> </ul> </li> </ul> </li> <li>Example Code <pre><code>import requests\n\nurl = \"http://127.0.0.1:8000/api/results/filter_host\"\n\n# Get Filtered Host\nresponse = requests.get(url)\n\n# Add Filtered Host\n#response = requests.post(url, params={\"ip\": \"2.17.188.84\"})\n\n# Delete Filtered Host\n#response = requests.delete(url, params={\"ip\": \"2.17.188.84\"})\n\nprint(response.text)\n</code></pre></li> </ul>"},{"location":"beacon_huntress/api/#interactive-api-docs","title":"Interactive API Docs","text":"<ol> <li>To access the interactive API docs click on the API Swagger link at the bottom of the page</li> </ol> <ol> <li>From the docs page you can run any of the api by expanding the requst, clicking the Try it out button, then the execute button and if successful you will receive a response body.</li> </ol>"},{"location":"beacon_huntress/api/#coding-example","title":"Coding Example","text":"<p>Below is an example of running a beacon searching using the API.</p>"},{"location":"beacon_huntress/api/#run-a-beacon-search","title":"Run a Beacon Search","text":"<p>Quick cluster search with the tutorial data.</p> <pre><code>import requests\nimport json\n\nurl = \"http://127.0.0.1:8000/api/searches/quick_cluster\"\npayload = {\n  \"log_type\": \"conn\",\n  \"log_dir\": \"/tutorial\",\n  \"delta\": 20,\n  \"call_back\": 10,\n  \"percent\": 85,\n  \"span_avg\": 12,\n  \"variance\": 15,\n  \"start_dte\": \"\",\n  \"end_dte\": \"\",\n  \"zip\": False,\n  \"verbose\": False\n}\npayload = json.dumps(payload)\n\n# Run Quick Cluster Search\nresponse = requests.post(url, data=payload)\nval = response.json()\n\n# Get Results\nurl = \"http://127.0.0.1:8000/api/results/beacon_results\"\nresponse = requests.get(url,params={\"beacon_group\": val[\"beacon_group\"]})\nprint(val[\"beacon_group\"])\nprint(response.text)\n</code></pre>"},{"location":"beacon_huntress/dashboard/","title":"Beacon Huntress Dashboard Overview","text":"<p>Beacon Huntress provides a Grafana dashboard to assist with finding beacons. When using Docker, the dashboard is the best resource for visualizing and analyzing the details of potential beacons. Log into Grafana by visiting the link below in your web browser. Credentials can be found in the dashboard configuration file located at src/config/dashboard.conf.</p> <p>Beacon Huntress Dashboard URL: http://127.0.0.1:3000</p>"},{"location":"beacon_huntress/dashboard/#beacon","title":"Beacon","text":"<p>The main dashboard is called Beacon. Clicking on the panels will provide additional information about the data shown. The Beacon dashboard includes the following panels:</p> <ol> <li>Total Records (clickable)</li> <li>Delta Connections (clickable)</li> <li>Potential Beacons (clickable)</li> <li>Potential Beacons Connections Over Time<pre><code>- Timeline of the beacon connections present in the provided files.\n</code></pre> </li> </ol> <p></p>"},{"location":"beacon_huntress/dashboard/#total-records","title":"Total Records","text":"<p>The Total Records panel will show the total number of Bro/Zeek connections contained in your logs. Clicking on the panel will take you to the File Details dashboard, which will display the source file location, the number of total connections in the file, and the number of connections that are potential beacons.</p> <p></p>"},{"location":"beacon_huntress/dashboard/#delta-connections","title":"Delta Connections","text":"<p>The Delta Connections panel will display the total number of Delta Connections found in the logs. A Delta Connection is a unique grouping of repeated connections between a Source IP and a Destination IP; these may or may not be labeled as Potential Beacons depending on the parameters used when configuring your cluster search algorithms; see the Beacon Algorithms section for more information on setting up your configuration file. Clicking on the panel will take you to the Delta Details dashboard, which provides additional information on each of the identified Delta Connections. Each connection listing will show the Source IP, Destination IP, Port, minimum and maximum times between connections, total connection count, average delta in milliseconds, and average delta in minutes. Clicking on the Destination IP link will open a dashboard that displays the cluster groupings for the deltas.</p> <p></p>"},{"location":"beacon_huntress/dashboard/#potential-beacons","title":"Potential Beacons","text":"<p>The Potential Beacons panel will display the total number of potential beacons that Beacon Huntress has identified based on your configuration file. Click on the Destination IP link to go to the Beacon Details dashboard. This screen will display the cluster groupings and provide additional information from the Bro/Zeek logs such as Connection Duration, Source/Destination Bytes, and Connection State. In the example below, the deltas are closely clustered in several groups, and there is little variation in the delta times between each connection event. Low variance in deltas is typically a good indication of a potential beacon.</p> <p></p>"},{"location":"beacon_huntress/datasource/","title":"Beacon Huntress Data Sources","text":"<p>Beacon Huntress now has the ability to store data sources to allow repeatable usage. Current data types are Zeek Connection Logs, Elastic Indices, and Security Onion Indices. Beacon Huntress defaults to the Zeek Connection Logs data source, which allows the user to select their raw Zeek connection logs. For details on setting up an API Key, please click the link.</p>"},{"location":"beacon_huntress/datasource/#elastic","title":"Elastic","text":"<p>The Elastic data source will use Zeek connection logs contained inside of the application. The indices will be manually selected. Click the link for details on setting up an API.</p> <p>To create an Elastic data source, follow the steps below.</p> <ol> <li>Under \"Settings\" click \"Data Sources\".</li> <li>Click the \"New\" button.</li> </ol> <p></p> <ol> <li> <p>Select \"Elastic\" in the \"Data Source Type\" drop-down list.</p> </li> <li> <p>The following inputs are required for Elastic:</p> <ul> <li>Data Source Name</li> <li>Unique name for your data source.</li> <li>Host</li> <li>Elastic Host Name.</li> <li>Port</li> <li>Elastic Port Name.</li> <li>API Key</li> <li>Elastic API Name.</li> <li>API Key can be viewed by clicking the eye button.</li> <li>Index</li> <li>Elastic Index Name (Multi-Select).</li> <li>Click the button to load the indices. You must have the correct Host, Port and API Key in order to load the indices. <p></p> <ol> <li>Click the \"Add\" button to create the new data source.</li> </ol> <p></p> <ol> <li>The new data source will now be available for any \"Search For Beacon\" data source.</li> </ol> <p></p>"},{"location":"beacon_huntress/datasource/#security-onion","title":"Security Onion","text":"<p>The Security Onion data source will use Zeek connection logs contained inside of the application. The indices will be automatically selected. Click the link for details on setting up an API.</p> <ol> <li>Under \"Settings\" click \"Data Sources\".</li> <li>Click the \"New\" button.</li> </ol> <p></p> <ol> <li> <p>Select \"Elastic\" in the \"Data Source Type\" drop-down list.</p> </li> <li> <p>The following inputs are required for Security Onion:</p> <ul> <li>Data Source Name</li> <li>Unique name for your data source.</li> <li>Host</li> <li>Security Onion Elastic Host Name.</li> <li>Port</li> <li>Security Onion Elastic Port Name.</li> <li>API Key</li> <li>Security Onion Elastic API Name.</li> <li>API Key can be viewed by clicking the eye button.</li> </ul> </li> </ol> <p></p> <ol> <li>Click \"Add\" button to create the new data source.</li> </ol> <p></p> <ol> <li>The new data source will now be available for any \"Search For Beacon\" data source.</li> </ol> <p></p>"},{"location":"beacon_huntress/datasource/#zeek-logs","title":"Zeek Logs","text":"<p>Zeek Connection Logs must be provided for Beacon Huntress to analyze. Follow the steps below to copy your Zeek logs from their initial location to a local directory that can be accessed by Beacon Huntress. It's recommended to organize the logs into separate directories, with each directory corresponding to a single day.</p> <ol> <li>In this example, we will copy Zeek connection logs to the <code>/zeek</code> directory. The <code>/zeek</code> directory is mounted to the Docker container beacon_huntress.</li> </ol> <pre><code># CREATE DIRECTORY (REPLACE YYYY-MM-DD WITH DATE)\nmkdir -p /zeek/raw/data/YYYY-MM-DD\n\n# START SFTP SHELL\nsftp root@YOUR_FTP_SERVER\n\n# SFTP COMMAND EXAMPLE (REPLACE YYYY-MM-DD WITH DATE)\nget -R zeek/logs/YYYY-MM-DD/conn.* /zeek/raw/data/YYYY-MM-DD\n</code></pre> <ol> <li>Under \"Settings\" click \"Data Sources\".</li> <li>Click the \"New\" button.</li> </ol> <p></p> <ul> <li> <p>The following inputs are required for Zeek Connection Logs:</p> </li> <li> <p>Data Source Name</p> <ul> <li>Unique name for your data source.</li> </ul> </li> <li> <p>Raw Log Location</p> <ul> <li>Raw Zeek file location.</li> </ul> </li> <li> <p>Click \"Add\" button to create the new data source.</p> </li> </ul> <p></p> <ol> <li>The new data source will now be available for any \"Search For Beacon\" data source.</li> </ol> <p></p>"},{"location":"beacon_huntress/datasource/#create-elastic-api","title":"Create Elastic API","text":"<p>Elastic and Security Onion data sources can be accessed by using the Elastic API. In order to use these data sources you must set up an Elastic API Key.</p> Note <p>Elastic Indices must be Zeek Connection Logs. Beacon Huntress only works with Zeek Connection Logs.</p> <ol> <li>From the Elastic Management Console, navigate to \"Security\" then \"API Keys\".</li> </ol> <p></p> <ol> <li>Click on the \"Create API Key\" button.</li> </ol> <p></p> <ol> <li>Give the API key the name \"bh_api\" and restrict permissions according to your organization's security policies. Finally, click the \"Create API Key\" button.</li> </ol> <p></p> <ol> <li>Copy the API key for Beacon Huntress usage.</li> </ol> Note <p>Once you leave the screen, the API key will not be retrievable. Best practice is to store the API key in a password safe.</p> <p></p>"},{"location":"beacon_huntress/defaultfilteredhosts/","title":"Default Filtered Hosts","text":"<p>Default Filtered Hosts is a list of popular websites that have been filtered out from Beacon Huntress results. These sites will not appear on the Filtered Hosts page of the Web UI. The complete list is below.</p> Site 365scores.com accuweather.com adobe.com aliexpress.com allrecipes.com amazon.co.jp amazon.co.uk amazon.com amazon.de amazon.es amazon.fr amazon.in apple.com ar.wikipedia.org baidu.com bbc.co.uk bbc.com booking.com britannica.com ca.wikipedia.org cambridge.org canva.com cashapp.com chatgpt.com clevelandclinic.org cnn.com cookpad.com craigslist.com cricbuzz.com cvs.com cvs.com de.wikipedia.org discord.com duckduckgo.com ebay.com eci.gov.in en.wikipedia.org es.wikipedia.org espn.com espncricinfo.com etsy.com facebook.com fandom.com finance.yahoo.com flipkart.com forbes.com fr.wikipedia.org github.com globo.com goal.com google.com healthline.com hi.wikipedia.org hindustantimes.com hollywoodbets.net homedepot.com huawei.com id.wikipedia.org ikea.com imdb.com indeed.com indianexpress.com indiatimes.com instagram.com investing.com investopedia.com it.wikipedia.org ja.wikipedia.org kompas.com linkedin.com live.com lowes.com mail.yahoo.com mayoclinic.org medicalnewstoday.com medlineplus.gov merriam-webster.com microsoft.com mlb.com moneycontrol.com nba.com ndtv.com netflix.com news18.com nfl.com nhl.com nih.gov nike.com nl.wikipedia.org nytimes.com openai.com paypal.com pinterest.com pl.wikipedia.org play.google.com playstation.com primevideo.com pt.wikipedia.org quora.com reddit.com roblox.com rottentomatoes.com ru.wikipedia.org samsung.com sharepoint.com shutterstock.com skysports.com slideshare.net smallpdf.com speedtest.net spotify.com steampowered.com support.google.com target.com telegram.org thehindu.com tiktok.com tr.wikipedia.org tradingview.com translate.google.com tripadvisor.com trustpilot.com turkiye.gov.tr twitch.tv twitter.com venmo.com walmart.com weather.com webmd.com whatsapp.com wiktionary.org wise.com www.gov.br www.gov.uk www.nhs.uk yahoo.co.jp yahoo.com yelp.com zh.wikipedia.org"},{"location":"beacon_huntress/interface/","title":"Beacon Huntress User Interface","text":"<p>This page outlines the usage and functionalities of the Beacon Huntress UI.</p>"},{"location":"beacon_huntress/interface/#execute","title":"Execute","text":"<p>The Execute tab has three sections: Quick Cluster Search, Cluster Search, and Hierarchical Search. For more information on Beacon Huntress algorithm configurations, see Beacon Huntress Algorithms.</p>"},{"location":"beacon_huntress/interface/#settings","title":"Settings","text":""},{"location":"beacon_huntress/interface/#data-sources","title":"Data Sources","text":"<p>The Data Sources section contains the data sources for Beacon Huntress. Reusable data sources are now available in Beacon Huntress. Current Data Source types are Zeek Connection Logs, Security Onion and Elastic.</p> Note <p>Beacon Huntress uses Zeek Connection Logs to find beacons. Elastic data sources must use Zeek Connection indices.</p> <ol> <li>Navigate to the Settings tab and click on Data Sources.</li> </ol> <p></p> <ol> <li>Zeek Connection Logs is the default data source, and the source file location is entered at run time. To add a new data source, click the New button.</li> </ol> <p></p> <ol> <li>Select a Data Source Type from the drop-down list. Input fields will be dynamically generated based upon the chosen type.</li> </ol> <p></p>"},{"location":"beacon_huntress/interface/#zeek-connection-logs","title":"Zeek Connection Logs","text":"<p>Zeek Connection Logs are raw Zeek connection logs.</p> <p></p> <ul> <li> <p>The following inputs are required for Zeek Connection Logs:</p> </li> <li> <p>Data Source Name</p> <ul> <li>Unique name for your data source.</li> </ul> </li> <li> <p>Raw Log Location</p> <ul> <li>Raw Zeek file location.</li> </ul> </li> </ul>"},{"location":"beacon_huntress/interface/#security-onion","title":"Security Onion","text":"<p>Security Onion data source will use Zeek connection logs contained inside of the application. The indices will be automatically selected. Click API Key for more details.</p> <p></p> <ul> <li> <p>The following inputs are required for Security Onion:</p> </li> <li> <p>Data Source Name</p> <ul> <li>Unique name for your data source.</li> </ul> </li> <li>Host<ul> <li>Security Onion Elastic Host Name.</li> </ul> </li> <li>Port<ul> <li>Security Onion Elastic Port Name.</li> </ul> </li> <li>API Key<ul> <li>Security Onion Elastic API Name.</li> <li>API Key can be viewed by clicking the eye button.</li> </ul> </li> </ul>"},{"location":"beacon_huntress/interface/#elastic","title":"Elastic","text":"<p>Elastic data source will use Zeek connection logs contained inside of the application. The indices will be automatically selected. Click API Key for more details.</p> <p></p> <ul> <li> <p>The following inputs are required for Elastic:</p> </li> <li> <p>Data Source Name</p> <ul> <li>Unique name for your data source.</li> </ul> </li> <li>Host<ul> <li>Elastic Host Name.</li> </ul> </li> <li>Port<ul> <li>Elastic Port Name.</li> </ul> </li> <li>API Key<ul> <li>Elastic API Name.   API Key can be viewed by clicking the eye button.</li> </ul> </li> <li>Index<ul> <li>Elastic Index Name (Multi-Select).   Click the button to load the indices. You must have the correct Host, Port and API Key in order to load the indices.</li> </ul> </li> </ul>"},{"location":"beacon_huntress/interface/#filters","title":"Filters","text":"<p>This section allows for the configuration of additional IP and port filtering. Filtering at this level will include/exclude certain results before the beacon algorithm runs.</p> <ol> <li>Navigate to Settings and click on Filters.</li> </ol> <p></p> <ol> <li> <p>The following parameters can be changed:</p> </li> <li> <p>Filter</p> <ul> <li>Checkbox to turn filter settings on or off.     Checked = Apply filters    Unchecked = Do not apply filters</li> </ul> </li> <li>Port Filter<ul> <li>A list of ports, in comma delimited format.</li> </ul> </li> <li>Port Filter Exclusive<ul> <li>Checkbox to determine whether the ports in the Port Filter list are included or excluded from results.    Checked = Excluded    Unchecked = Included</li> </ul> </li> <li>Source IP Filter<ul> <li>A list of Source IPs, in comma delimited format.</li> </ul> </li> <li>Source IP Filter Exclusive<ul> <li>Checkbox to determine whether the IPs in the Source IP Filter list are included or excluded from results.    Checked = Excluded    Unchecked = Included</li> </ul> </li> <li>Destination IP Filter<ul> <li>A list of Destination IPs, in comma delimited format.</li> </ul> </li> <li>Destination IP Filter Exclusive<ul> <li>Checkbox to determine whether the IPs in the Destination IP Filter list are included or excluded from results.    Checked = Excluded    Unchecked = Included</li> </ul> </li> </ol>"},{"location":"beacon_huntress/interface/#filtered-hosts","title":"Filtered Hosts","text":"<p>The Filtered Hosts section will display any additional IP addresses that have been manually excluded from the beacon results. IPs that have been excluded from results using the Filters settings will not be displayed here. You can remove an IP address from this list by clicking on the \"Trash Can\" icon.  </p>"},{"location":"beacon_huntress/interface/#default-filtered-hosts","title":"Default Filtered Hosts","text":"<p>Default Filtered Hosts is a premade list of popular websites that are automatically filtered out from the results. These sites will not appear on the Filtered Hosts page. To see the complete list, go to the Default Filtered Hosts page.</p>"},{"location":"beacon_huntress/interface/#results","title":"Results","text":"<p>You can navigate through results found by Beacon Huntress using the options on the Results page. Click on \"Group ID\" to view potential beacons. Select \"Dashboard\" to display those results in a Grafana dashboard. Click on \"Log File\" to view the run logs. Choose \"Config\" to display the runtime configuration. Select \"Delete\" to PERMANENTLY remove the result set.</p> <p></p>"},{"location":"beacon_huntress/interface/#logs","title":"Logs","text":"<p>The Logs section holds the runtime logs for each Beacon Huntress execution. Logs can also be accessed via the Results page.</p> <ol> <li>Navigate to Logs.</li> </ol> <p></p> <ol> <li>Click on \"File Name\" to pull the details.</li> </ol> <p></p>"},{"location":"beacon_huntress/jupyter/","title":"Beacon Huntress for  Jupyter Notebooks","text":"<p>Complete the steps below to set up Beacon Huntress on Jupyter.</p> Note <p>Beacon Huntress has Python dependencies that are required for operation. Do not skip steps 5 &amp; 6 from the setup!</p>"},{"location":"beacon_huntress/jupyter/#juptyer-notebook-setup","title":"Juptyer Notebook Setup","text":"<ol> <li>Create a folder in Jupyter called <code>beacon_huntress</code>.</li> <li>Copy the <code>/src/lib/jupyter/beacon_huntress.ipynb</code> file from this repository into the beacon_huntress folder in Jupyter.</li> <li>Copy the <code>/src/bin/beacon/beacon.py</code> folder from this repository into Jupyter.</li> <li>Copy the <code>/src/bin/ingest.py</code> folder from this repository into Jupyter.</li> <li>Copy the <code>/src/lib/jupyter/requirements.txt</code> file into the beacon_huntress folder in Jupyter.</li> <li>Open a Jupyter terminal session and execute the code below to install the requirements.txt into a Jupyter kernel called beacon_huntress.</li> </ol> <pre><code># CREATE VIRTUAL ENV\npython3 -m venv beacon_huntress\n\n# ACTIVATE VIRTUAL ENV\nsource $HOME/beacon_huntress/bin/activate\n\n# INSTALL REQUIREMENTS FILE\npip3 install -r beacon_huntress/requirements.txt\n\n# LOAD KERNEL TO JUPYTER\nsudo ipython kernel install --name \"beacon_huntress\"\n</code></pre> <p>After everything is installed you should see this structure:</p> <p></p>"},{"location":"beacon_huntress/jupyter/#run-jupyter-notebook","title":"Run Jupyter Notebook","text":"<p>Open beacon_huntress.ipynb inside a Jupyter notebook. Run the steps below.</p> <ol> <li> <p>Run the <code>BUILD BRONZE DATA LAYER</code> shell.</p> </li> <li> <p>src_loc (string)       Raw Bro/Zeek logs folder.</p> </li> <li>bronze_loc (string)      Bronze folder location. Folder where data will be compressed and converted to Parquet format.</li> </ol> <pre><code>import ingest\n\n# BUILD BRONZE DATA LAYER\ningest.build_bronze_layer(\n    src_loc=\"data/raw/data\",\n    bronze_loc=\"data/bronze/zeek/raw/parquet/mc3\"\n    )\n</code></pre> <ol> <li> <p>Run the <code>CREATE FILTERED FILES</code> shell to filter files.</p> </li> <li> <p>src_loc (string)      Raw Bro/Zeek logs folder.</p> </li> <li>dest_exclude_file (string)      Destination folder location for non-matching filters. Matches are excluded from the results..      Use a unique folder name at the end to identify your filter - a data folder will be appended automatically.      Pass a blank double quote (\"\") to skip the creation of an exclude file.</li> <li>port_filter (list)      Ports that you want to include, in list format.</li> </ol> <pre><code># CREATE FILTERED FILES\n# SEE README.MD FOR ADDITIONAL OPTIONS\ningest.build_filter_files(\nsrc_loc = \"data/bronze/zeek/raw/parquet/mc3\",\ndest_exclude_file = \"data/bronze/zeek/filtered/parquet\",\nport_filter = [80, 443]\n)\n</code></pre> <ol> <li> <p>Run the <code>BUILD DELTA FILES</code> shell to build the delta files.</p> </li> <li> <p>src_file (string)      Source folder or file location.</p> </li> <li>delta_file_loc (string)      Destination folder or file location for delta files.</li> </ol> <pre><code># BUILD DELTA FILES\ningest.build_delta_files(src_loc = \"data/bronze/zeek/filtered/parquet\",\n                     delta_file_loc = \"data/silver/delta\")\n</code></pre> <ol> <li> <p>Choose the algorithm that you want to run and configure the settings. Some examples are included below, but see the Beacon Algorithms page for more details.</p> </li> <li> <p>Agglomerative Clustering</p> <pre><code>import beacon\n\n# AGGLOMERATIVE CLUSTERING\n# SLOW BEACON\nbeacon.agglomerative_clustering(\n   delta_file = \"data/silver/delta/delta_1655318432.parquet\",\n   delta_column = \"delta_mins\",\n   max_variance = .12,\n   min_records = 10,\n   cluster_factor = .70,\n   line_amounts = [1],\n   min_delta_time = 1200000\n)\n</code></pre> </li> <li> <p>DBSCAN Clustering</p> <pre><code>import beacon\n\n# DBSCAN\n# SLOW BEACON\nbeacon.dbscan_clustering(\n    delta_file = \"data/silver/delta/delta_1655318432.parquet\",,\n    delta_column = \"delta_mins\",\n    spans = [[0, 5], [2, 15], [15, 35], [30, 60]],\n    minimum_delta = 20,\n    minimum_points_in_cluster = 10,\n    minimum_likelihood = 0.70\n)\n</code></pre> </li> <li> <p>DBSCAN by Variance</p> <pre><code>import beacon\n\n# DBSCAN by VARIANCE\n# SLOW BEACON\nbeacon.dbscan_by_variance(\n    delta_file = \"data/silver/delta/delta_1655318432.parquet\",\n    delta_column = \"delta_mins\",\n    avg_delta = 20,\n    conn_cnt = 10,\n    span_avg = 15,\n    variance_per = 15,\n    minimum_likelihood = 70\n)\n</code></pre> </li> </ol>"},{"location":"beacon_huntress/modules/","title":"Beacon Huntress Modules","text":"<p>There are two main modules that can be used for the beacon detection data pipeline: beacon.py and ingest.py. Beacon.py is used for beacon detection. Ingest.py is used for creating the data pipeline. Modules should only be used in a Juypter Notebook environment."},{"location":"beacon_huntress/modules/#beaconpy","title":"beacon.py","text":"<p>The Beacon module is used to run various beacon detection algorithms against an ingest-created delta file. Currently all delta files used within this module must be in Parquet format.</p> Note <p>Ensure that you have the <code>__pycache__</code> directory in the same location as the beacon.py file.</p>"},{"location":"beacon_huntress/modules/#import-module","title":"Import Module","text":"<pre><code>import beacon\n</code></pre> <p>These are the available methods:</p> <ul> <li>agglomerative_clustering()</li> <li>cli_results()</li> <li>cluster_conns()</li> <li>dbscan_clustering()</li> <li>dbscan_by_variance()</li> <li>get_dns()</li> </ul>"},{"location":"beacon_huntress/modules/#note","title":"Note","text":"<p>Any changes made to the beacon.py module within JuypterLab will require a reload of the beacon.py module. Use the code below to reload the beacon.py module.</p>"},{"location":"beacon_huntress/modules/#reload-module","title":"Reload Module","text":"<pre><code>import importlib\nimported_module = importlib.import_module(\"beacon\")\nimportlib.reload(imported_module)\nimport beacon\n</code></pre>"},{"location":"beacon_huntress/modules/#agglomerative_clusteringkwargs","title":"agglomerative_clustering(**kwargs)","text":"<p>Run an agglomerative clustering algorithm against a delta file to identify cluster points to be used to find a beacon.</p>"},{"location":"beacon_huntress/modules/#request-syntax","title":"Request Syntax","text":"<pre><code>import beacon\n\nrequest = beacon.agglomerative_clustering(\n    delta_file = \"string\",\n    delta_column = \"string\",\n    max_variance = float,\n    min_records = int,\n    cluster_factor = float,\n    line_amounts = [ int, ],\n    min_delta_time = int,\n    gold_loc = \"string\",\n    cli_return = True|False,\n    overwrite = True|False,\n    verbose = True|False\n)\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters","title":"Parameters","text":"<ul> <li> <p>delta_file (string) -- [REQUIRED]   Source delta file.</p> </li> <li> <p>delta_column (string)   Source delta column that you want to search. Options (below) are ms = milliseconds and mins = minutes Options   _ delta_ms   _ delta_mins</p> </li> <li> <p>max_variance (float) -- [REQUIRED]   Variance threshold for any potential beacons.</p> </li> <li> <p>min_records (int) -- [REQUIRED]   Minimum number of delta records to search.</p> </li> <li> <p>cluster_factor (float) -- [REQUIRED]   The likelihood percentage for a cluster.</p> </li> <li> <p>line_amounts (list) -- [REQUIRED]   Line amounts to process at a time, in list format.</p> </li> <li> <p>min_delta_time (string) -- [REQUIRED]   Minimum delta time to search by, in milliseconds.</p> </li> <li> <p>gold_loc (string)    Results file location. Blank string (\"\") for no result file Default = \"\"</p> </li> <li> <p>cli_return (boolean)    Return Command Line Interface (CLI) results. Will display as a print statement and not a return variable. Default = True</p> </li> <li> <p>overwrite (boolean)    Overwrite existing files. True or False (case-sensitive). Default = False</p> </li> <li> <p>verbose (boolean)    Verbose logging. True or False (case-sensitive). Default = False</p> </li> </ul>"},{"location":"beacon_huntress/modules/#returns","title":"Returns","text":"<p>Gold file (string)</p>"},{"location":"beacon_huntress/modules/#example-run","title":"Example Run","text":"<pre><code>import beacon\n\ngold_file = beacon.agglomerative_clustering(\n    delta_file = \"/tmp/delta/delta_file.parquet\",\n    max_variance = 0.01,\n    min_records = 10,\n    cluster_factor = 0.2,\n    line_amounts = [1],\n    min_delta_time = 300000,\n    gold_loc = \"/tmp/gold/beacon/agg_cluster\",\n    cli_return = False\n)\n\nprint(gold_file)\n</code></pre>"},{"location":"beacon_huntress/modules/#cli_resultskwargs","title":"cli_results(**kwargs)","text":"<p>Return Command Line Interface (CLI) results from a gold file. Results will be printed to the screen.</p>"},{"location":"beacon_huntress/modules/#request-syntax_1","title":"Request Syntax","text":"<pre><code>import beacon\n\nrequest = beacon.cli_results(\n    gold_file = \"string\",\n    file_type = \"string\n)\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_1","title":"Parameters","text":"<ul> <li> <p>gold_file (string) --[REQUIRED]   Gold file location.</p> </li> <li> <p>file_type (string) --[REQUIRED]   Gold file type (CSV or Parquet). Default = \"parquet\"</p> </li> </ul>"},{"location":"beacon_huntress/modules/#returns_1","title":"Returns","text":"<p>None</p>"},{"location":"beacon_huntress/modules/#example-run_1","title":"Example Run","text":"<pre><code>import beacon\n\nbeacon.cli_results(\n    gold_file = \"/tmp/gold/data/12345678.parquet\"\n)\n</code></pre>"},{"location":"beacon_huntress/modules/#cluster_connskwargs","title":"cluster_conns(**kwargs)","text":"<p>Return Command Line Interface (CLI) results from a gold file. Results will be printed to the screen.</p>"},{"location":"beacon_huntress/modules/#request-syntax_2","title":"Request Syntax","text":"<pre><code>import beacon\n\nrequest = beacon.cluster_conns(\n    delta_file = \"string\",\n    delta_column = \"string\",\n    conn_cnt = int,\n    conn_group = int,\n    threshold = int,\n    gold_loc = \"string\",\n    cli_return = True|False,\n    overwrite = True|False,\n    verbose = True|False\n)\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_2","title":"Parameters","text":"<ul> <li> <p>delta_file (string) -- [REQUIRED]   Source delta file.</p> </li> <li> <p>delta_column (string) --[REQUIRED]   Source delta column that you want to search.</p> </li> <li> <p>conn_cnt (int)   Total connection count for a group. Greater than or equal (&gt;=). Default = 10</p> </li> <li> <p>conn_group (int)   Total number of connection groups. Greater than or equal (&gt;=). Default = 5</p> </li> <li> <p>threshold (int)   The time threshold in minutes when determining connection groups. Default = 60</p> </li> <li> <p>gold_loc (string)   Results file location. Blank string (\"\") for no result file Default = \"\"</p> </li> <li> <p>cli_return (boolean)    Return Command Line Interface (CLI) results. Will display as a print statement and not a return variable. Default = True</p> </li> <li> <p>overwrite (boolean)   Overwrite existing files. True or False (case-sensitive). Default = False</p> </li> <li> <p>verbose (boolean)   Verbose logging. True or False (case-sensitive). Default = False</p> </li> </ul>"},{"location":"beacon_huntress/modules/#returns_2","title":"Returns","text":"<p>Gold file (string)</p>"},{"location":"beacon_huntress/modules/#example-run_2","title":"Example Run","text":"<pre><code>import beacon\n\ngold_file = beacon.cluster_conns(\n    delta_file = \"/tmp/delta/delta_file.parquet\",\n    delta_column = \"delta_mins\",\n    conn_cnt = 10,\n    conn_group = 5,\n    threshold = 60,\n    gold_loc = \"/tmp/gold/beacon/dbscan\",\n    cli_return = False,\n    overwrite = False,\n    verbose = False\n)\n\nprint(gold_file)\n</code></pre>"},{"location":"beacon_huntress/modules/#dbscan_clusteringkwargs","title":"dbscan_clustering(**kwargs)","text":"<p>Run a DBSCAN cluster algorithm against a delta file to identify cluster points to be used to find a beacon.</p>"},{"location":"beacon_huntress/modules/#request-syntax_3","title":"Request Syntax","text":"<pre><code>import beacon\n\nrequest = beacon.dbscan_clustering(\n    delta_file = \"string\",\n    delta_column = \"string\",\n    minimum_delta = int,\n    spans = [[ int, int ], [ int, int], ],\n    minimum_points_in_cluster = int,\n    minimum_likelihood = float,\n    gold_loc = \"string\",\n    cli_return = True|False,\n    overwrite = True|False,\n    verbose = True|False\n)\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_3","title":"Parameters","text":"<ul> <li> <p>delta_file (string) --[REQUIRED]   Source delta file.</p> </li> <li> <p>delta_column (string) --[REQUIRED]   Source delta column that you want to search.</p> </li> <li> <p>minimum_delta (int) --[REQUIRED]   Minimum number of delta records to search using your delta column.</p> </li> <li> <p>spans (list)    Spans of time that you wish to search, in list format. Example: Will search within two time spans, 0-5 min and 5-10 min. [[0, 5], [5, 10]] Default = [] <li> <p>minimum_points_in_cluster (int)   Destination file type (CSV or Parquet). Default = 4</p> </li> <li> <p>minimum_likelihood (float)    Likelihood value (threshold) used to identify a potential beacon. Default = .70</p> </li> <li> <p>gold_loc (string)   Results file location. Blank string (\"\") for no result file Default = \"\"</p> </li> <li> <p>cli_return (boolean)    Return Command Line Interface (CLI) results. Will display as a print statement and not a return variable. Default = True</p> </li> <li> <p>overwrite (boolean)   Overwrite existing files. True or False (case-sensitive). Default = False</p> </li> <li> <p>verbose (boolean)   Verbose logging. True or False (case-sensitive). Default = False</p> </li>"},{"location":"beacon_huntress/modules/#returns_3","title":"Returns","text":"<p>Gold file (string)</p>"},{"location":"beacon_huntress/modules/#example-run_3","title":"Example Run","text":"<pre><code>import beacon\n\ngold_file = beacon.dbscan_clustering(\n    delta_file = \"/tmp/delta/delta_file.parquet\",\n    delta_column = \"delta_mins\",\n    minimum_delta = 1,\n    spans = [[0, 5], [2, 15], [15, 35], [30, 60]],\n    minimum_points_in_cluster = 4,\n    minimum_likelihood = 0.70,\n    gold_loc = \"/tmp/gold/beacon/dbscan\",\n    cli_return = False\n)\n\nprint(gold_file)\n</code></pre>"},{"location":"beacon_huntress/modules/#dbscan_by_variancekwargs","title":"dbscan_by_variance(**kwargs)","text":"<p>Run a DBSCAN cluster by filtering out records by delta variance percentage and average delta time. Source delta file must be in Parquet format.</p>"},{"location":"beacon_huntress/modules/#request-syntax_4","title":"Request Syntax","text":"<pre><code>import beacon\n\nrequest = beacon.dbscan_by_variance(\n    delta_file = \"string\",\n    delta_column = \"string\",\n    avg_delta = int,\n    conn_cnt = int,\n    span_avg = int,\n    variance_per = int,\n    minimum_likelihood = float,\n    gold_loc = \"string\",\n    cli_return = True|False,\n    overwrite = True|False,\n    verbose = True|False\n)\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_4","title":"Parameters","text":"<ul> <li> <p>delta_file (string) --[REQUIRED]   Source delta file.</p> </li> <li> <p>delta_column (string) --[REQUIRED]   Source delta column that you want to search.</p> </li> <li> <p>avg_delta (int) --[REQUIRED]   Average delta time to include in the search using your delta column. Less than or equal (&lt;=).</p> </li> <li> <p>conn_cnt (int)   Total connection count for filtering. Greater than or equal (&gt;=). Default = 4</p> </li> <li> <p>span_avg (int)    The percentage to increase and decrease from the connections total delta span. Example: 15 will increase/decrease the minimum and maximum of the delta span by 15%. delta min = 5 delta max = 10 span min = 4.25 (5 - (5 _ 15%)) span max = 11.5 (10 + (10 _ 15%)) Default = 15 <li> <p>variance_per (int)   Total variance percentage for filtering. Greater than or equal (&gt;=). Default = 4</p> </li> <li> <p>gold_loc (string)   Results file location. Blank string (\"\") for no result file Default = \"\"</p> </li> <li> <p>cli_return (boolean)    Return Command Line Interface (CLI) results. Will display as a print statement and not a return variable. Default = True</p> </li> <li> <p>overwrite (boolean)    Overwrite existing files. True or False (case-sensitive). Default = False</p> </li> <li> <p>verbose (boolean)   Verbose logging. True or False (case-sensitive). Default = False</p> </li>"},{"location":"beacon_huntress/modules/#returns_4","title":"Returns","text":"<p>Gold file (string)</p>"},{"location":"beacon_huntress/modules/#example-run_4","title":"Example Run","text":"<pre><code>import beacon\n\ngold_file = beacon.dbscan_by_variance(\n    delta_file = \"/tmp/delta/delta_file.parquet\",\n    delta_column = \"delta_mins\",\n    avg_delta = 10,\n    conn_cnt = 5,\n    span_avg = 15,\n    variance_per = 10,\n    minimum_likelihood = 0.70,\n    gold_loc = \"/tmp/gold/beacon/dbscan_var\",\n    cli_return = False\n)\n\nprint(gold_file)\n</code></pre>"},{"location":"beacon_huntress/modules/#get_dnskwargs","title":"get_dns(**kwargs)","text":"<p>Look up a DNS record for an IP.</p>"},{"location":"beacon_huntress/modules/#request-syntax_5","title":"Request Syntax","text":"<pre><code>import beacon\n\nrequest = beacon.get_dns(\n    ip = \"string\"\n)\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_5","title":"Parameters","text":"<ul> <li>ip (list) --[REQUIRED]   IP for which you want to look up a DNS entry. Default = None</li> </ul>"},{"location":"beacon_huntress/modules/#returns_5","title":"Returns","text":"<p>DNS Value (string)</p>"},{"location":"beacon_huntress/modules/#example-run_5","title":"Example Run","text":"<pre><code>import beacon\n\ndns = beacon.get_dns(\n    ip = \"127.0.0.1\"\n)\n\nprint(dns)\n</code></pre>"},{"location":"beacon_huntress/modules/#packetkwargs","title":"packet(**kwargs)","text":"<p>Run a Beacon search by packet size uniqueness.</p>"},{"location":"beacon_huntress/modules/#request-syntax_6","title":"Request Syntax","text":"<pre><code>import beacon\n\nrequest = beacon.packet(\n    delta_file = \"string\",\n    delta_column = \"string\",\n    avg_delta = int,\n    conn_cnt = int,\n    min_unique_percent = int,\n    gold_loc = \"string\",\n    cli_return = True|False,\n    overwrite = True|False,\n    verbose = True|False\n)\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_6","title":"Parameters","text":"<ul> <li> <p>delta_file (string) -- [REQUIRED]   Source delta file.</p> </li> <li> <p>delta_column (string) --[REQUIRED]   Source delta column that you want to search.</p> </li> <li> <p>avg_delta (int) --[REQUIRED]   Average delta time to include in the search using your delta column. Less than or equal (&lt;=).</p> </li> <li> <p>conn_cnt (int)   Total connection count for a group. Greater than or equal (&gt;=). Default = 5</p> </li> <li> <p>min_unique_percent (int)   Lowest packet uniqueness as a percentage. For instance, if you have 10 connections with 9 of them being the same packet size, your unique package size is 10%. Default = 5</p> </li> <li> <p>threshold (int)   The time threshold in minutes for determining connection groups. Default = 60</p> </li> <li> <p>gold_loc (string)   Results file location. Blank string (\"\") for no result file Default = \"\"</p> </li> <li> <p>cli_return (boolean)    Return Command Line Interface (CLI) results. Will display as a print statement and not a return variable. Default = True</p> </li> <li> <p>overwrite (boolean)   Overwrite existing files. True or False (case-sensitive). Default = False</p> </li> <li> <p>verbose (boolean)   Verbose logging. True or False (case-sensitive). Default = False</p> </li> </ul>"},{"location":"beacon_huntress/modules/#returns_6","title":"Returns","text":"<p>Gold file (string)</p>"},{"location":"beacon_huntress/modules/#example-run_6","title":"Example Run","text":"<pre><code>import beacon\n\ngold_file = beacon.packet(\n    delta_file = \"/tmp/delta/delta_file.parquet\",\n    delta_column = \"delta_mins\",\n    avg_delta = 15,\n    conn_cnt = 5,\n    min_unique_percent = 5,\n    gold_loc = \"/tmp/gold/beacon/dbscan\",\n    cli_return = False,\n    overwrite = False,\n    verbose = False\n)\n\nprint(gold_file)\n</code></pre>"},{"location":"beacon_huntress/modules/#ingestpy","title":"ingest.py","text":"<p>Below are the steps for loading the ingest.py module. Ensure that you have the <code>__pycache__</code> directory in the same location as the ingest.py file.</p> <pre><code>import ingest\n</code></pre> <p>Any changes done to the ingest.py module within JuypterLab will require a reload of the ingest.py module. Use the code below to reload the ingest.py module.</p> <pre><code>import importlib\nimported_module = importlib.import_module(\"ingest\")\nimportlib.reload(imported_module)\nimport ingest\n</code></pre> <p>These are the available methods:</p> <ul> <li>add_dns()</li> <li>build_bronze_layer()</li> <li>build_delta_files()</li> <li>build_filter_files()</li> <li>build_null_files()</li> <li>build_raw()</li> <li>convert_parquet_to_csv()</li> <li>download_s3_folder()</li> <li>filter_dataframe()</li> <li>get_latest_file()</li> <li>unzip()</li> </ul>"},{"location":"beacon_huntress/modules/#add_dnskwargs","title":"add_dns(**kwargs)","text":"<p>Add source and destination DNS entries to file(s) based upon a whitelist Parquet file or Pandas DataFrame. Both the source and destination files need to be in Parquet format.</p>"},{"location":"beacon_huntress/modules/#request-syntax_7","title":"Request Syntax","text":"<pre><code>import ingest\n\nrequest = ingest.add_dns(\n    src_file = \"string\",\n    dest_loc = \"string\",\n    file_type = \"string\",\n    dns_file = \"string\"\n    dns_df = Pandas_DataFrame,\n    verbose = True|False\n)\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_7","title":"Parameters","text":"<ul> <li> <p>src_file (string) --[REQUIRED]   Source folder or file location.</p> </li> <li> <p>dest_loc (string) --[REQUIRED]   Destination folder or file location.</p> </li> <li> <p>file_type (string) --[REQUIRED]   Destination file type (CSV or Parquet). Parquet format recommended!</p> </li> <li> <p>dns_file (string)    Source DNS lookup file. A blank string is the default. The lookup file must be in Parquet format. Default = \"\"</p> </li> <li> <p>dns_df (Pandas DataFrame)    Source DNS Pandas DataFrame. A blank string is the default. Default = \"\"</p> </li> <li> <p>verbose (boolean)   Verbose logging. True or False (case-sensitive). Default = False</p> </li> </ul>"},{"location":"beacon_huntress/modules/#returns_7","title":"Returns","text":"<p>None</p>"},{"location":"beacon_huntress/modules/#example-run_7","title":"Example Run","text":"<pre><code>import ingest\n\n# Folder Location\ningest.add_dns(\n    src_file = \"/tmp/source_files\",\n    dest_loc = \"/tmp/dest_files\",\n    dns_file = \"/tmp/whitelist/whitelist_ip.parquet\"\n)\n\n# Single File\ningest.add_dns(\n    src_file = \"/tmp/source_files/source_file.parquet\",\n    dest_loc = \"/tmp/dest_files\",\n    dns_file = \"/tmp/whitelist/whitelist_ip.parquet\"\n)\n</code></pre>"},{"location":"beacon_huntress/modules/#build_bronze_layerkwargs","title":"build_bronze_layer(**kwargs)","text":"<p>Create a bronze data layer for a source folder location. Bronze data will contain TCP data only and will include both source and destination DNS.</p>"},{"location":"beacon_huntress/modules/#request-syntax_8","title":"Request Syntax","text":"<pre><code>import ingest\n\nrequest = ingest.build_bronze_layer(\n    src_loc = \"string\",\n    bronze_loc = \"string\",\n    dns_file = \"string\",\n    overwrite = True|False,\n    verbose = True|False\n)\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_8","title":"Parameters","text":"<ul> <li> <p>src_file (string) --[REQUIRED]   Raw source folder location.</p> </li> <li> <p>bronze_loc (string) --[REQUIRED]   Bronze layer folder location. The destination location for all bronze files.</p> </li> <li> <p>dns_file (string)    Source DNS lookup file. The lookup file must be in Parquet format.</p> </li> <li> <p>overwrite (boolean)    Overwrite existing files. True or False (case-sensitive). Default = False</p> </li> <li> <p>verbose (boolean)   Verbose logging. True or False (case-sensitive). Default = False</p> </li> </ul>"},{"location":"beacon_huntress/modules/#returns_8","title":"Returns","text":"<p>None</p>"},{"location":"beacon_huntress/modules/#example-run_8","title":"Example Run","text":"<pre><code>import ingest\n\ningest.build_bronze_layer(\n    src_loc=\"/tmp/source/\",\n    bronze_loc=\"/tmp/bronze/zeek/raw/parquet/2022/04/22\",\n    dns_file = \"/tmp/whitelist/whitelist_ip.parquet\"\n    )\n</code></pre>"},{"location":"beacon_huntress/modules/#build_delta_fileskwargs","title":"build_delta_files(**kwargs)","text":"<p>Create a delta file from a Parquet folder location or file. Current units of measurement are milliseconds and minutes. Source and destination files must be in Parquet format. </p> <p>Note Destination files are named delta_epochtime.parquet.</p>"},{"location":"beacon_huntress/modules/#request-syntax_9","title":"Request Syntax","text":"<pre><code>import ingest\n\nrequest = ingest.build_delta_files(\n    src_loc = \"string\",\n    delta_file_loc = \"string\",\n    delta_file_type = \"string\",\n    overwrite = True|False,\n    )\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_9","title":"Parameters","text":"<ul> <li> <p>src_file (string) --[REQUIRED]   Source folder or file location.</p> </li> <li> <p>delta_file_loc (string) --[REQUIRED]   Destination folder or file location for delta files.</p> </li> <li> <p>delta_file_type (string)   Destination file type (CSV or Parquet). Parquet format is recommended! Default = parquet</p> </li> <li> <p>overwrite (boolean)    Overwrite existing files. True or False (case-sensitive). Default = False</p> </li> </ul>"},{"location":"beacon_huntress/modules/#returns_9","title":"Returns","text":"<p>None</p>"},{"location":"beacon_huntress/modules/#example-run_9","title":"Example Run","text":"<pre><code>import ingest\n\ningest.build_delta_files(\n    src_loc = \"/tmp/filtered/\",\n    delta_file_loc = \"/tmp/delta\"\n    )\n</code></pre>"},{"location":"beacon_huntress/modules/#build_filter_fileskwargs","title":"build_filter_files(**kwargs)","text":"<p>Create filtered files by searching for Ports, Source/Destination IPs or DNS entries. A default metadata.json will be created for historical filter identification purposes.</p>"},{"location":"beacon_huntress/modules/#request-syntax_10","title":"Request Syntax","text":"<pre><code>import ingest\n\nrequest = ingest.build_filter_files(\n    src_loc = \"string\",\n    dest_file = \"string\",\n    port_filter = [ int, ],\n    port_exclude = True|False,\n    src_file = [ \"string\", ],\n    src_exclude = True|False,\n    dest_filter = [ \"string\", ],\n    dest_exclude = True|False,\n    s_dns_filter = [ \"string\", ],\n    s_dns_exclude = True|False,\n    d_dns_filter = [ \"string\", ],\n    d_dns_exclude = True|False,\n    match_filter = [ \"string\", ],\n    match_exclude = True|False,\n    file_type = \"string\",\n    overwrite = True|False,\n    verbose = True|False\n    )\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_10","title":"Parameters","text":"<ul> <li> <p>src_file (string) --[REQUIRED]   Source folder location.</p> </li> <li> <p>dest_file (string)   Destination file location for filters.   Use a unique folder name at the end to identify your filter - a data folder will be appended automatically. Default = \"\"</p> </li> <li> <p>port_filter (list)   Ports that you want to filter by, in a list format. Inclusive results only. Default = None</p> </li> <li> <p>port_exclude (boolean)   Exclusive or inclusive search on port_filter values. True or False (case-sensitive).   Exclusive = True (not in)   Inclusive = False (in) Default = False</p> </li> <li> <p>src_filter (list)   Source IP that you want to filter by, in a list format. Default search will look for items equal to match.   Use of a wildcard (*) will perform a wildcard search. Default = None</p> </li> <li> <p>src_exclude (boolean)   Exclusive or inclusive search on src_filter values. True or False (case-sensitive).   Exclusive = True (not in)   Inclusive = False (in) Default = True</p> </li> <li> <p>dest_filter (list)   Destination DNS that you want to filter by, in a list format. Default search will look for items equal to match.   Use of a wildcard (*) will perform a wildcard search. Default = None</p> </li> <li> <p>dest_exclude (boolean)   Exclusive or inclusive search on dest_filter values. True or False (case-sensitive).   Exclusive = True (not in)   Inclusive = False (in) Default = True</p> </li> <li> <p>s_dns_filter (list)   Source DNS that you want to filter by, in a list format. Default search will look for items equal to match.   Use of a wildcard (*) will perform a wildcard search. Default = None</p> </li> <li> <p>s_dns_exclude (boolean)   Exclusive or inclusive search on s_dns_filter values. True or False (case-sensitive).   Exclusive = True (not in)   Inclusive = False (in) Default = True</p> </li> <li> <p>d_dns_filter (list)   Destination DNS that you want to filter by, in a list format. Default search will look for items equal to match.   Use of a wildcard (*) will perform a wildcard search. Default = None</p> </li> <li> <p>d_dns_exclude (boolean)   Exclusive or inclusive search on d_dns_filter values. True or False (case-sensitive).   Exclusive = True (not in)   Inclusive = False (in) Default = True</p> </li> <li> <p>match_filter (list)   Source and Destination DNS that you want to filter by, in a list format. Default search will look for items equal to match.   Use of a wildcard (*) will perform a wildcard search. In order to match, objects must be in both source and destination. Default = None</p> </li> <li> <p>match_exclude (boolean)   Exclusive or inclusive search on match_filter values. True or False (case-sensitive).   Exclusive = True (not in)   Inclusive = False (in) Default = True</p> </li> <li> <p>file_type (string)    Destination file types. Parquet or CSV. Parquet format is recommended! Default = parquet</p> </li> <li> <p>overwrite (boolean)    Overwrite existing location. True or False (case-sensitive). Default = False</p> </li> <li> <p>verbose (boolean)   Verbose logging. True or False (case-sensitive). Default = False</p> </li> </ul>"},{"location":"beacon_huntress/modules/#returns_10","title":"Returns","text":"<p>None</p>"},{"location":"beacon_huntress/modules/#example-run_10","title":"Example Run","text":"<pre><code>import ingest\n\n# NO INCLUDE FILE\n# ONLY PORTS 80 &amp; 443 WILL BE INCLUDED.\n# EXAMPLE IPS WILL BE REMOVED.\ningest.build_filter_files(\n    src_loc = \"/tmp/source\",\n    dest_file = \"/tmp/dest/filtered/test_filter\"\n    port_filter = [80, 443],\n    src_filter = [\"127.0.0.1\", \"9.9.9.9\"],\n    dest_filter = [\"127.0.0.1\", \"9.9.9.9\"])\n</code></pre>"},{"location":"beacon_huntress/modules/#build_null_fileskwargs","title":"build_null_files(**kwargs)","text":"<p>Create filter files with NULL DNS entries.</p>"},{"location":"beacon_huntress/modules/#request-syntax_11","title":"Request Syntax","text":"<pre><code>import ingest\n\nrequest = ingest.build_null_files(\n    src_loc = \"string\",\n    dest_loc = \"string\",\n    overwrite = True|False,\n    file_type = \"string\"\n    )\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_11","title":"Parameters","text":"<ul> <li> <p>src_file (string) --[REQUIRED]   Source folder or file location.</p> </li> <li> <p>dest_loc (string) --[REQUIRED]   Destination folder location.</p> </li> <li> <p>overwrite (boolean)    Overwrite existing location. True or False (case-sensitive). Default = False</p> </li> <li> <p>file_type (string)    Destination file types. Parquet or CSV. Parquet format is recommended! Default = parquet</p> </li> </ul>"},{"location":"beacon_huntress/modules/#returns_11","title":"Returns","text":"<p>None</p>"},{"location":"beacon_huntress/modules/#example-run_11","title":"Example Run","text":"<pre><code>import ingest\n\ningest.build_null_files(\n    src_loc = \"/tmp/source\",\n    dest_loc = \"/tmp/filtered/no_match\")\n</code></pre>"},{"location":"beacon_huntress/modules/#build_rawkwargs","title":"build_raw(**kwargs)","text":"<p>Build initial Parquet file from raw JSON Zeek file. To be used only for single files. Use build_bronze_layer() for folder-level processing.</p>"},{"location":"beacon_huntress/modules/#request-syntax_12","title":"Request Syntax","text":"<pre><code>import ingest\n\ningest.build_raw(\n    src_loc = \"string\",\n    dest_loc = \"string\",\n    overwrite = True|False,\n    verbose = True|False\n    )\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_12","title":"Parameters","text":"<ul> <li> <p>src_file (string) --[REQUIRED]   Source file.</p> </li> <li> <p>dest_parquet_file (string) --[REQUIRED]   Destination Parquet file.</p> </li> <li> <p>overwrite (boolean)    Overwrite existing files. True or False (case-sensitive). Default = False</p> </li> <li> <p>verbose (boolean)   Verbose logging. True or False (case-sensitive). Default = False</p> </li> </ul>"},{"location":"beacon_huntress/modules/#returns_12","title":"Returns","text":"<p>None</p>"},{"location":"beacon_huntress/modules/#example-run_12","title":"Example Run","text":"<pre><code>import ingest\n\ningest.build_raw(\n    src_loc = \"/tmp/source/test.json\",\n    dest_loc = \"/tmp/raw/test.parquet\"\n    )\n</code></pre>"},{"location":"beacon_huntress/modules/#convert_parquet_to_csvkwargs","title":"convert_parquet_to_csv(**kwargs)","text":"<p>Create a CSV file from a Parquet file.</p>"},{"location":"beacon_huntress/modules/#request-syntax_13","title":"Request Syntax","text":"<pre><code>import ingest\n\nrequest = ingest.convert_parquet_to_csv(\n    par_file = \"string\",\n    csv_file = \"string\"\n    )\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_13","title":"Parameters","text":"<ul> <li> <p>par_file (string) --[REQUIRED]   Source Parquet file.</p> </li> <li> <p>csv_file (string) --[REQUIRED]   Destination CSV file.</p> </li> </ul>"},{"location":"beacon_huntress/modules/#returns_13","title":"Returns","text":"<p>None</p>"},{"location":"beacon_huntress/modules/#example-run_13","title":"Example Run","text":"<pre><code>import ingest\n\ningest.convert_parquet_to_csv(\n    par_file = \"/tmp/source/test.parquet\",\n    csv_file = \"/tmp/dest/test.csv\"\n    )\n</code></pre>"},{"location":"beacon_huntress/modules/#download_s3_folderkwargs","title":"download_s3_folder(**kwargs)","text":"<p>Download an AWS S3 folder to a local folder. Must have an AWS CLI Profile configured.</p>"},{"location":"beacon_huntress/modules/#example-run_14","title":"Example Run","text":"<pre><code>import ingest\n\nrequest = ingest.download_s3_folder(\n    s3_loc = \"string\",\n    csv_file = \"string\",\n    profile = \"string\"\n    )\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_14","title":"Parameters","text":"<ul> <li> <p>s3_loc (string) --[REQUIRED]   S3 folder location.</p> </li> <li> <p>local_dest (string) --[REQUIRED]   Local destination folder.</p> </li> <li> <p>profile (string)   AWS CLI Profile name. Default = default</p> </li> </ul>"},{"location":"beacon_huntress/modules/#returns_14","title":"Returns","text":"<p>None</p>"},{"location":"beacon_huntress/modules/#example-run_15","title":"Example Run","text":"<pre><code>import ingest\n\ningest.download_s3_folder(\n    s3_loc = \"s3://bucket/foldername\",\n    csv_file = \"/tmp/bucketname/foldername\")\n</code></pre>"},{"location":"beacon_huntress/modules/#filter_dataframekwargs","title":"filter_dataframe(**kwargs)","text":"<p>Filter a Zeek Pandas Dataframe for matching values. Returns a Pandas Dataframe.</p>"},{"location":"beacon_huntress/modules/#request-syntax_14","title":"Request Syntax","text":"<pre><code>import ingest\n\nrequest = ingest.filter_dataframe(\n    df = Pandas_DataFrame,\n    filter_vals = [ \"string\", ],\n    filter_column = \"string\",\n    filter_type = \"string\",\n    ret_org = True|False,\n    verbose = True|False\n    )\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_15","title":"Parameters","text":"<ul> <li> <p>df (pandas dataframe) --[REQUIRED]   Pandas Dataframe.</p> </li> <li> <p>filter_vals (list) --[REQUIRED]   Values that you want to filter by, in a list format.</p> <p>String values search types: Default search will look for items equal to match.   Use of a wildcard (*) will perform a wildcard search.</p> </li> <li> <p>filter_column (string) --[REQUIRED]   Pandas DataFrame column that you want to search by. Case sensitive.</p> <p>Valid Options       * community_id        * conn_state        * duration        * history        * id.orig_h        * id.orig_p        * id.resp_h        * id.resp_p        * local_orig        * local_resp        * missed_bytes        * orig_bytes        * orig_ip_bytes        * orig_pkts        * proto        * resp_bytes        * resp_ip_bytes        * resp_pkts        * service        * ts        * uid </p> </li> </ul> <p></p> <ul> <li> <p>filter_type (string) --[REQUIRED]   The type of filter that you are using. Valid Options   _ int (integer)   _ string (string) * match (matching Source and Destination DNS values)</p> </li> <li> <p>ret_org (boolean)   Return original dataframe if no results gathered. True or False (case-sensitive). Default = False</p> </li> <li> <p>verbose (boolean)   Verbose logging. True or False (case-sensitive). Default = False</p> </li> </ul>"},{"location":"beacon_huntress/modules/#returns_15","title":"Returns","text":"<p>Pandas Dataframe</p>"},{"location":"beacon_huntress/modules/#example-run_16","title":"Example Run","text":"<pre><code>import ingest\nimport pandas as pd\n\nsrc_df = pd.read_parquet(\"/tmp/dest/test.parquet\")\n\nnew_df = ingest.filter_dataframe(\n    df = src_df,\n    filter_vals = [\"127.0.0.1\", \"localhost\"],\n    filter_column = \"id.orig_h\",\n    filter_type = \"string\"\n    )\n\nprint(new_df)\n</code></pre>"},{"location":"beacon_huntress/modules/#get_latest_filekwargs","title":"get_latest_file(**kwargs)","text":"<p>Get the most recent file from a folder location. Method is used to grab the latest delta or gold file. Returns a full path.</p>"},{"location":"beacon_huntress/modules/#request-syntax_15","title":"Request Syntax","text":"<pre><code>import ingest\n\nrequest = ingest.get_latest_file(\n    folder_loc = \"string\",\n    file_type = \"string\"\n    )\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_16","title":"Parameters","text":"<ul> <li> <p>folder_loc (string) --[REQUIRED]   Source folder location.</p> </li> <li> <p>file_type (string)    Destination file type that you want to search for. Parquet or CSV. Parquet format is recommended! Default = parquet</p> </li> </ul>"},{"location":"beacon_huntress/modules/#example-run_17","title":"Example Run","text":"<pre><code>import ingest\n\n# PULL LATEST DELTA FILE\nmax_file = ingest.filter_dataframe(\n    folder_loc = \"/tmp/delta/\"\n    )\n\nprint(max_file)\n</code></pre>"},{"location":"beacon_huntress/modules/#unzipkwargs","title":"unzip(**kwargs)","text":"<p>Unzip a raw source file. Only tar files are available for unzipping.</p>"},{"location":"beacon_huntress/modules/#request-syntax_16","title":"Request Syntax","text":"<pre><code>import ingest\n\nrequest = ingest.unzip(\n    zip_file = \"string\",\n    dest_loc = \"string\",\n    file_type = \"string\"\n    )\n</code></pre>"},{"location":"beacon_huntress/modules/#parameters_17","title":"Parameters","text":"<ul> <li> <p>zip_file (string) --[REQUIRED]   Source zip file.</p> </li> <li> <p>dest_loc (string) --[REQUIRED]   Destination folder where the zip file will be extracted. Parquet format is recommended! Default = parquet</p> </li> <li> <p>dest_loc (string)    Zip file type. Currently the only valid option is tar Valid Options * tar Default = tar</p> </li> </ul> <pre><code>import ingest\n\ningest.unzip(\n    zip_file = \"/tmp/aw_data_file.tar\",\n    dest_loc = \"/tmp/raw/data\"\n    )\n</code></pre>"},{"location":"beacon_huntress/tutorial/","title":"Beacon Huntress Tutorial","text":"<p>This tutorial will provide an example for running Beacon Huntress using a generic dataset.</p> Note <p>You must complete the Docker Setup prior to running this tutorial.</p> <ol> <li>Visit http://127.0.0.1:8000 in your web browser to access the main page of the Beacon Huntress Web UI.</li> </ol> <p></p> <ol> <li> <p>Go to the \"Search For Beacons\" tab and select \"Quick Cluster\".</p> </li> <li> <p>Change the \"Data Source\" to \"Zeek Connection Logs\" and set the \"Raw Log Location\" to <code>/tutorial</code>. Click \"Run\" to perform a beacon search. The execution will take a moment.</p> </li> </ol> <p></p> <ol> <li>After the execution is finished, you'll be redirected to the results page. For this dataset, the \"Beacon Count\" column shows that two potential beacons have been identified. Several options are now available. Click on \"Group ID\" to view the potential beacons. Click the \"Dashboard\" icon to display results in a Grafana dashboard. Click on the \"Log File\" icon to view the run logs. Click the \"Config\" icon to display runtime configuration. Click the \"Delete\" icon to PERMANENTLY remove this result set.</li> </ol> <p></p> <ol> <li>Click \"Group ID\" to view potential beacons. In this example, Beacon Huntress has identified two potential beacons: 7.7.7.1 and 2.17.188.84 (\"fandango.com\"). The 7.7.7.1 connection is our target test beacon, but the connections to \"fandango.com\" are benign traffic. Since the identification of \"fandango.com\" as a beacon is incorrect, we will exclude this result from the current and future runs by clicking the \"Filter\" icon.</li> </ol> <p></p> <ol> <li>Now, the results from \"fandango.com\" are filtered out.</li> </ol> <p></p> <ol> <li>To view all of your filtered hosts, go to the \"Settings\" tab and select \"Filtered Hosts\". Filtered hosts can be removed from this list by clicking the \"Trash Can\" icon in the \"Option\" column, which will cause them to once again appear in the results.</li> </ol> <p></p> <ol> <li>Go back to the \"Results\" tab and click on the \"Dashboard\" icon.</li> </ol> <p></p> <ol> <li>A Grafana dashboard will open in a new browser tab. See Dashboard for more details on dashboard usage and functionality.</li> </ol> <p></p>"},{"location":"beacon_huntress/tutorial/#congratulations-you-have-completed-your-first-beacon-huntress-test-run","title":"Congratulations! You have completed your first Beacon Huntress test run!","text":""},{"location":"beacon_huntress/tutorial/#zeek-logs","title":"Zeek Logs","text":"<p>Zeek Connection Logs must be provided for Beacon Huntress to analyze. Follow the steps below to copy your Zeek logs from their initial location to a local directory that can be accessed by Beacon Huntress. It's recommended that you organize the logs into separate directories, with each directory corresponding to a single day.</p> <ol> <li>In this example, we will copy Zeek connection logs to the <code>/zeek</code> directory. The <code>/zeek</code> directory is mounted to the Docker container beacon_huntress.</li> </ol> <pre><code># CREATE DIRECTORY (REPLACE YYYY-MM-DD WITH DATE)\nmkdir -p /zeek/raw/data/YYYY-MM-DD\n\n# START SFTP SHELL\nsftp root@YOUR_FTP_SERVER\n\n# SFTP COMMAND EXAMPLE (REPLACE YYYY-MM-DD WITH DATE)\nget -R zeek/logs/YYYY-MM-DD/conn.* /zeek/raw/data/YYYY-MM-DD\n</code></pre> <ol> <li>When you run a beacon search, select \"Zeek Connection Logs\" as a \"Data Source\" and then change the \"Raw Log Location\" to <code>/zeek</code>. This will run the search on the Zeek connection logs.</li> </ol> <p></p>"},{"location":"ip_maven/","title":"IP Maven","text":"<p>IP Maven is a comprehensive DNS analysis service designed to provide detailed insights into IP addresses and their associated netblock records. It offers both online and offline capabilities, making it a versatile tool for network administrators, security professionals, and analysts.</p> <p>By combining traditional Zeek DNS logs with enriched netblock information, IP Maven delivers a holistic view of network traffic. This fusion enables more accurate threat detection, enhanced network visibility, and improved diagnostics of network behavior.</p>"},{"location":"ip_maven/#key-features","title":"Key Features","text":"<ul> <li>Netblock Enrichment: Seamlessly integrates IP addresses with detailed netblock information for more insightful analysis.</li> <li>Offline Analysis: Perform in-depth investigations using archived data without relying on continuous online queries.</li> <li>Zeek Integration: Works in conjunction with Zeek logs to enhance DNS analysis with enriched IP intelligence.</li> <li>User-Friendly Interface: Simplifies the process of viewing, searching, and interpreting DNS and netblock data.</li> <li>Extensible Framework: Designed for customization and integration into existing network monitoring pipelines.</li> </ul>"},{"location":"ip_maven/#why-use-ip-maven","title":"Why Use IP Maven?","text":"<p>IP Maven bridges the gap between raw DNS logs and actionable insights by adding critical context to IP addresses. Here\u2019s why it\u2019s a valuable addition to your toolkit:</p> <ul> <li>Enhanced Network Visibility: See the \"big picture\" of your network traffic by associating IPs with their respective netblocks.</li> <li>Improved Threat Detection: Detect unusual patterns or anomalies with enriched data.</li> <li>Faster Incident Response: Investigate incidents with comprehensive information at your fingertips.</li> <li>Offline Functionality: Access and analyze data even in air-gapped or restricted environments.</li> </ul>"},{"location":"ip_maven/#license","title":"License","text":"<p>[DISTRIBUTION STATEMENT A] This material has been approved for public release and unlimited distribution. Copyright 2023 Carnegie Mellon University. See the license file for more details.</p>"},{"location":"ip_maven/additionalresources/","title":"Additional Resources for IP Maven","text":"<ul> <li>Netblock Providers: Refer to the following netblock providers for additional information that they may provide:<ul> <li>ARIN</li> <li>RIPE NCC</li> <li>APNIC</li> <li>LACNIC</li> <li>AFRINIC</li> </ul> </li> <li>Data Sources: The following data sources may be useful for IP Maven:<ul> <li>MaxMind</li> <li>IP2Location</li> <li>IPinfo</li> <li>IP Geolocation API</li> </ul> </li> <li>Contributing: We welcome contributions! Please see our Contribution Guidelines.</li> </ul>"},{"location":"ip_maven/faqs/","title":"IP Maven Frequently Asked Questions","text":"<ol> <li> <p>What is the purpose of combining Zeek logs with netblock information?</p> <p>Combining Zeek DNS logs with netblock data provides enhanced visibility into the origin and ownership of IP addresses, allowing for more comprehensive traffic analysis and anomaly detection.</p> </li> <li> <p>Can IP Maven operate in air-gapped environments?</p> <p>Yes, IP Maven supports offline operation by allowing you to preload all required data files. Ensure that the netblock data is updated periodically in environments with limited internet access.</p> </li> <li> <p>How often should I update netblock information?</p> <p>Netblock data updates depend on your provider's frequency. It is recommended that you update the data monthly or as specified by your licensing agreement.</p> </li> </ol>"},{"location":"ip_maven/quickstart/","title":"IP Maven Quick Start","text":"<p>Due to licensing restrictions on some of the data used by IP Maven, the application does not include netblock information by default. To load the necessary data and start using IP Maven, follow these steps:</p>"},{"location":"ip_maven/quickstart/#step-1-prepare-the-environment","title":"Step 1: Prepare the Environment","text":"<ul> <li>Ensure that you have installed Python 3.8+ and the required dependencies.</li> <li>Clone the IP Maven repository from GitHub:</li> </ul> <pre><code>git clone https://github.com/cmu-sei/Valkyrie_Framework\ncd valkyrie_framework/ip_maven\n</code></pre>"},{"location":"ip_maven/quickstart/#step-2-acquire-licensing-data","title":"Step 2: Acquire Licensing Data","text":"<ul> <li>Obtain the necessary netblock data files from approved providers.</li> <li>Licensing agreements may require you to download and update these files periodically.</li> <li>Save the netblock data files to the data/ directory within the IP Maven project.</li> </ul>"},{"location":"ip_maven/quickstart/#step-3-install-dependencies","title":"Step 3: Install Dependencies","text":"<ul> <li>Use the following command to install all required dependencies:</li> </ul> <pre><code>pip install -r requirements.txt\n\n# If python manage.py results in ModuleNotFoundError: No module named 'pkg_resources'\n# https://stackoverflow.com/questions/7446187/no-module-named-pkg-resources\npip install setuptools\n\npython manage.py makemigrations ipmaven_www\npython manage.py migrate\n</code></pre>"},{"location":"ip_maven/quickstart/#step-4-load-netblock-information","title":"Step 4: Load Netblock Information","text":"<ul> <li>Load the netblock data into IP Maven using the provided script:</li> </ul> <pre><code>python ../scripts/load_csv_to_database.py --db ../src/ipmaven_www/db.sqlite3 --csv ../_data/import/out/arin_db.csv\n</code></pre> <p>Verify the data load by checking the application logs for success messages.</p> <p>The output should be similar to:</p> <pre><code>CSV data imported into 'import2' table successfully.\nData moved to 'ipmaven_www_whois' table and temporary table dropped.\n</code></pre>"},{"location":"ip_maven/quickstart/#step-5-start-the-application","title":"Step 5: Start the Application","text":"<ul> <li>Launch IP Maven:</li> </ul> <pre><code>python manage.py runserver 127.0.0.1:8000\n</code></pre> <p>By default, the service runs on http://localhost:8000. You can modify the port and configuration settings in the config.yaml file.</p>"},{"location":"ip_maven/quickstart/#step-6-integration-with-zeek","title":"Step 6: Integration with Zeek","text":"<ul> <li>Configure Zeek to export DNS logs to a directory accessible by IP Maven.</li> </ul> <p>The app is now ready to use.</p>"}]}